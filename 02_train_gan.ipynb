{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/*\n",
    "# %cd /kaggle/working\n",
    "# !git clone https://github.com/TAYDOVAT/Cuoi_Ki_DL.git\n",
    "# %cd /kaggle/working/Cuoi_Ki_DL\n",
    "\n",
    "# !rm -r /kaggle/working/Cuoi_Ki_DL/test\n",
    "# !rm -r /kaggle/working/Cuoi_Ki_DL/train\n",
    "# !rm -r /kaggle/working/Cuoi_Ki_DL/val\n",
    "\n",
    "# !cp -r \"/kaggle/input/anh-ve-tinh/Ảnh vệ tinh/test\" /kaggle/working/Cuoi_Ki_DL\n",
    "# !cp -r \"/kaggle/input/anh-ve-tinh/Ảnh vệ tinh/train\" /kaggle/working/Cuoi_Ki_DL\n",
    "# !cp -r \"/kaggle/input/anh-ve-tinh/Ảnh vệ tinh/val\" /kaggle/working/Cuoi_Ki_DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SRGAN x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecaef4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from data import build_loader\n",
    "from original_model import SRResNet, DiscriminatorForVGG\n",
    "from losses import PixelLoss, PerceptualLoss, AdversarialLoss\n",
    "from engine import train_gan_epoch, val_gan_epoch\n",
    "from vis import show_lr_sr_hr, plot_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd709ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config override here\n",
    "cfg = {\n",
    "    'scale': 4,\n",
    "    'hr_crop': 128,\n",
    "    'gan': {\n",
    "        'batch_size': 32,\n",
    "        'num_workers': 4,\n",
    "        'epochs': 200,\n",
    "        'lr_g': 5e-5,\n",
    "        'lr_d': 5e-6,\n",
    "        'adv_weight': 1e-3,\n",
    "        'perc_weight': 6e-3,\n",
    "        'pixel_weight': 1,\n",
    "    },\n",
    "    'paths': {\n",
    "        'train_lr': 'train/train_lr',\n",
    "        'train_hr': 'train/train_hr',\n",
    "        'val_lr': 'val/val_lr',\n",
    "        'val_hr': 'val/val_hr',\n",
    "        'test_lr': 'test/test_lr',\n",
    "        'test_hr': 'test/test_hr',\n",
    "    },\n",
    "}\n",
    "base_dir = None\n",
    "cwd = Path.cwd().resolve()\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    if (parent / 'train' / 'train_lr').is_dir():\n",
    "        base_dir = parent\n",
    "        break\n",
    "\n",
    "if base_dir is None:\n",
    "    raise FileNotFoundError(f\"Cannot find 'train/train_lr' from cwd: {cwd}\")\n",
    "\n",
    "cfg['paths']['train_lr'] = str(base_dir / 'train' / 'train_lr')\n",
    "cfg['paths']['train_hr'] = str(base_dir / 'train' / 'train_hr')\n",
    "cfg['paths']['val_lr'] = str(base_dir / 'val' / 'val_lr')\n",
    "cfg['paths']['val_hr'] = str(base_dir / 'val' / 'val_hr')\n",
    "cfg['paths']['test_lr'] = str(base_dir / 'test' / 'test_lr')\n",
    "cfg['paths']['test_hr'] = str(base_dir / 'test' / 'test_hr')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs('weights', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2aef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_loader = build_loader(\n",
    "    cfg['paths']['train_lr'], cfg['paths']['train_hr'],\n",
    "    scale=cfg['scale'], hr_crop=cfg['hr_crop'],\n",
    "    batch_size=cfg['gan']['batch_size'],\n",
    "    num_workers=cfg['gan']['num_workers'],\n",
    "    train=True\n",
    ")\n",
    "val_dataset, val_loader = build_loader(\n",
    "    cfg['paths']['val_lr'], cfg['paths']['val_hr'],\n",
    "    scale=cfg['scale'], hr_crop=cfg['hr_crop'],\n",
    "    batch_size=32,\n",
    "    num_workers=cfg['gan']['num_workers'],\n",
    "    train=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1388d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SRResNet(upscale=cfg['scale']).to(device)\n",
    "generator.load_state_dict(torch.load('weights/best_srresnet.pth', map_location=device))\n",
    "discriminator = DiscriminatorForVGG().to(device)\n",
    "\n",
    "pixel_criterion = PixelLoss().to(device)\n",
    "perceptual_criterion = PerceptualLoss().to(device)\n",
    "adversarial_criterion = AdversarialLoss().to(device)\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=cfg['gan']['lr_g'])\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=cfg['gan']['lr_d'])\n",
    "scheduler_g = lr_scheduler.StepLR(optimizer_g, step_size=50, gamma=0.5)\n",
    "scheduler_d = lr_scheduler.StepLR(optimizer_d, step_size=50, gamma=0.5)\n",
    "\n",
    "weights = {\n",
    "    'pixel': cfg['gan']['pixel_weight'],\n",
    "    'perceptual': cfg['gan']['perc_weight'],\n",
    "    'adversarial': cfg['gan']['adv_weight'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b17e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 [Train]:   0%|          | 0/1 [00:00<?, ?it/s]e:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 1/200 [Train]: 100%|██████████| 1/1 [00:59<00:00, 59.60s/it, loss_G=1.0181, loss_D=0.7083, psnr=34.35]\n",
      "Epoch 1/200 [Val]:   0%|          | 0/1 [00:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     29\u001b[39m train_stats = train_gan_epoch(\n\u001b[32m     30\u001b[39m     generator, discriminator, train_pbar,\n\u001b[32m     31\u001b[39m     optimizer_g, optimizer_d, device,\n\u001b[32m     32\u001b[39m     pixel_criterion, perceptual_criterion, adversarial_criterion,\n\u001b[32m     33\u001b[39m     weights\n\u001b[32m     34\u001b[39m )\n\u001b[32m     36\u001b[39m val_pbar = tqdm(val_loader, desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Val]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m val_stats = \u001b[43mval_gan_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_pbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpixel_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperceptual_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversarial_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m scheduler_g.step()\n\u001b[32m     44\u001b[39m scheduler_d.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VietHoang\\Desktop\\Cuoi_Ki_DL\\engine.py:169\u001b[39m, in \u001b[36mval_gan_epoch\u001b[39m\u001b[34m(generator, discriminator, loader, device, pixel_criterion, perceptual_criterion, adversarial_criterion, weights)\u001b[39m\n\u001b[32m    166\u001b[39m lr = lr.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    167\u001b[39m hr = hr.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m sr = \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m d_real = discriminator(hr)\n\u001b[32m    171\u001b[39m d_fake = discriminator(sr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VietHoang\\Desktop\\Cuoi_Ki_DL\\original_model.py:204\u001b[39m, in \u001b[36mSRResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VietHoang\\Desktop\\Cuoi_Ki_DL\\original_model.py:209\u001b[39m, in \u001b[36mSRResNet._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    208\u001b[39m     conv1 = \u001b[38;5;28mself\u001b[39m.conv1(x)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv2(x)\n\u001b[32m    211\u001b[39m     x = torch.add(x, conv1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VietHoang\\Desktop\\Cuoi_Ki_DL\\original_model.py:300\u001b[39m, in \u001b[36m_ResidualConvBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    298\u001b[39m     identity = x\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m     x = torch.add(x, identity)\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'loss_g': {'train': [], 'val': []},\n",
    "    'loss_d': {'train': [], 'val': []},\n",
    "    'psnr': {'train': [], 'val': []},\n",
    "    'ssim': {'train': [], 'val': []},\n",
    "    'd_real_prob': {'train': [], 'val': []},\n",
    "    'd_fake_prob': {'train': [], 'val': []},\n",
    "}\n",
    "log_dir = 'logs'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_path = os.path.join(log_dir, 'gan_log.csv')\n",
    "expected_header = [\n",
    "    'epoch',\n",
    "    'train_loss_g',\n",
    "    'val_loss_g',\n",
    "    'train_loss_d',\n",
    "    'val_loss_d',\n",
    "    'train_d_real_prob',\n",
    "    'val_d_real_prob',\n",
    "    'train_d_fake_prob',\n",
    "    'val_d_fake_prob',\n",
    "    'train_psnr',\n",
    "    'val_psnr',\n",
    "    'train_ssim',\n",
    "    'val_ssim',\n",
    "]\n",
    "needs_header = True\n",
    "if os.path.exists(log_path):\n",
    "    with open(log_path, 'r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        existing = next(reader, [])\n",
    "    if existing == expected_header:\n",
    "        needs_header = False\n",
    "\n",
    "if needs_header:\n",
    "    with open(log_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            'epoch',\n",
    "            'train_loss_g',\n",
    "            'val_loss_g',\n",
    "            'train_loss_d',\n",
    "            'val_loss_d',\n",
    "            'train_d_real_prob',\n",
    "            'val_d_real_prob',\n",
    "            'train_d_fake_prob',\n",
    "            'val_d_fake_prob',\n",
    "            'train_psnr',\n",
    "            'val_psnr',\n",
    "            'train_ssim',\n",
    "            'val_ssim',\n",
    "        ])\n",
    "best_psnr = -1.0\n",
    "epochs = cfg['gan']['epochs']\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{epochs} [Train]')\n",
    "    train_stats = train_gan_epoch(\n",
    "        generator, discriminator, train_pbar,\n",
    "        optimizer_g, optimizer_d, device,\n",
    "        pixel_criterion, perceptual_criterion, adversarial_criterion,\n",
    "        weights\n",
    "    )\n",
    "\n",
    "    val_pbar = tqdm(val_loader, desc=f'Epoch {epoch}/{epochs} [Val]')\n",
    "    val_stats = val_gan_epoch(\n",
    "        generator, discriminator, val_pbar, device,\n",
    "        pixel_criterion, perceptual_criterion, adversarial_criterion,\n",
    "        weights\n",
    "    )\n",
    "\n",
    "    scheduler_g.step()\n",
    "    scheduler_d.step()\n",
    "\n",
    "    history['loss_g']['train'].append(train_stats['loss_g'])\n",
    "    history['loss_g']['val'].append(val_stats['loss_g'])\n",
    "    history['loss_d']['train'].append(train_stats['loss_d'])\n",
    "    history['loss_d']['val'].append(val_stats['loss_d'])\n",
    "    history['d_real_prob']['train'].append(train_stats['d_real_prob'])\n",
    "    history['d_real_prob']['val'].append(val_stats['d_real_prob'])\n",
    "    history['d_fake_prob']['train'].append(train_stats['d_fake_prob'])\n",
    "    history['d_fake_prob']['val'].append(val_stats['d_fake_prob'])\n",
    "    history['psnr']['train'].append(train_stats['psnr'])\n",
    "    history['psnr']['val'].append(val_stats['psnr'])\n",
    "    history['ssim']['train'].append(train_stats['ssim'])\n",
    "    history['ssim']['val'].append(val_stats['ssim'])\n",
    "\n",
    "    with open(log_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            epoch,\n",
    "            train_stats['loss_g'],\n",
    "            val_stats['loss_g'],\n",
    "            train_stats['loss_d'],\n",
    "            val_stats['loss_d'],\n",
    "            train_stats['d_real_prob'],\n",
    "            val_stats['d_real_prob'],\n",
    "            train_stats['d_fake_prob'],\n",
    "            val_stats['d_fake_prob'],\n",
    "            train_stats['psnr'],\n",
    "            val_stats['psnr'],\n",
    "            train_stats['ssim'],\n",
    "            val_stats['ssim'],\n",
    "        ])\n",
    "\n",
    "    torch.save(generator.state_dict(), 'weights/last_gan.pth')\n",
    "    if val_stats['psnr'] > best_psnr:\n",
    "        best_psnr = val_stats['psnr']\n",
    "        torch.save(generator.state_dict(), 'weights/best_gan.pth')\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    rand_idx = random.randint(0, len(val_dataset) - 1)\n",
    "    lr_sample, hr_sample = val_dataset[rand_idx]\n",
    "    lr_in = lr_sample.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        sr_sample = generator(lr_in).cpu()\n",
    "    show_lr_sr_hr(lr_sample, sr_sample, hr_sample)\n",
    "\n",
    "    plot_curves(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(venv) Python 3.13.0 (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
