{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5523fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --branch Distributed-Data-Parallel https://github.com/TAYDOVAT/Cuoi_Ki_DL.git\n",
    "# %cd /kaggle/working/Cuoi_Ki_DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Train SRGAN x4 (DDP torchrun) - Single Config\n",
    "\n",
    "- Notebook nay dung 1 config train duy nhat (khong candidate/sweep).\n",
    "- Ban co the chon `G_LOSS_MODE = 'srgan'` hoac `'lpips_adv'` trong cell config.\n",
    "- Dieu khien phase bang `TRAIN_PHASE = 'phase1'` hoac `TRAIN_PHASE = 'phase2'`.\n",
    "- Quy uoc epoch tong:\n",
    "  - `phase1`: train den epoch 60, `resume=False`\n",
    "  - `phase2`: train tiep den epoch 120, `resume=True` tu `weights/srgan_60/checkpoint_srgan_60.pth`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from configs import CFG\n",
    "\n",
    "cfg = deepcopy(CFG)\n",
    "!pip install lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374af835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config override - Single config with 2-phase flow\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect data_root (Kaggle + local)\n",
    "candidates = [\n",
    "    Path('/kaggle/input/datasets/tyantran/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('/kaggle/input/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('../../input/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('../input/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('./datasets/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "]\n",
    "\n",
    "data_root = next((p.resolve() for p in candidates if p.exists()), None)\n",
    "if data_root is None:\n",
    "    raise FileNotFoundError('Khong tim thay data_root. Hay them candidate path phu hop may ban.')\n",
    "print('Using data_root:', data_root)\n",
    "\n",
    "# Paths\n",
    "cfg['paths']['train_lr'] = str(data_root / 'train' / 'train_lr')\n",
    "cfg['paths']['train_hr'] = str(data_root / 'train' / 'train_hr')\n",
    "cfg['paths']['val_lr'] = str(data_root / 'val' / 'val_lr')\n",
    "cfg['paths']['val_hr'] = str(data_root / 'val' / 'val_hr')\n",
    "cfg['paths']['test_lr'] = str(data_root / 'test' / 'test_lr')\n",
    "cfg['paths']['test_hr'] = str(data_root / 'test' / 'test_hr')\n",
    "\n",
    "# Shared runtime settings\n",
    "cfg['hr_crop'] = 96\n",
    "cfg['gan']['train_batch_size'] = 32\n",
    "cfg['gan']['val_batch_size'] = 12  # None -> auto by world_size\n",
    "cfg['gan']['num_workers'] = 4\n",
    "cfg['gan']['pin_memory'] = True\n",
    "cfg['gan']['persistent_workers'] = True\n",
    "cfg['gan']['use_amp'] = True\n",
    "cfg['gan']['use_lpips'] = True\n",
    "\n",
    "# Choose one loss mode: 'srgan' or 'lpips_adv'\n",
    "G_LOSS_MODE = 'srgan'\n",
    "cfg['gan']['g_loss_mode'] = G_LOSS_MODE\n",
    "\n",
    "# Shared GAN dynamics\n",
    "cfg['gan']['lr_g'] = 1e-4\n",
    "cfg['gan']['lr_d'] = 3e-5\n",
    "cfg['gan']['g_steps'] = 1\n",
    "cfg['gan']['d_steps'] = 1\n",
    "cfg['gan']['r1_weight'] = 2.0\n",
    "cfg['gan']['r1_interval'] = 8\n",
    "cfg['gan']['d_noise_std_start'] = 0.03\n",
    "cfg['gan']['d_noise_std_end'] = 0.005\n",
    "cfg['gan']['d_noise_decay_epochs'] = 60\n",
    "cfg['gan']['real_label'] = 0.9\n",
    "cfg['gan']['fake_label'] = 0.0\n",
    "cfg['gan']['val_use_train_labels'] = True\n",
    "cfg['gan']['scheduler_type'] = 'multistep'\n",
    "cfg['gan']['milestones'] = [60, 90]\n",
    "cfg['gan']['gamma'] = 0.5\n",
    "cfg['gan']['pixel_weight'] = 0.0\n",
    "\n",
    "# Mode-specific loss weights\n",
    "if G_LOSS_MODE == 'srgan':\n",
    "    cfg['gan']['perc_weight'] = 1.0\n",
    "    cfg['gan']['adv_weight'] = 1e-3\n",
    "    cfg['gan']['lpips_weight'] = 1.0  # compatibility only\n",
    "elif G_LOSS_MODE == 'lpips_adv':\n",
    "    cfg['gan']['perc_weight'] = 1.0  # kept for compatibility\n",
    "    cfg['gan']['adv_weight'] = 3e-3\n",
    "    cfg['gan']['lpips_weight'] = 1.0\n",
    "else:\n",
    "    raise ValueError(f'Unsupported G_LOSS_MODE: {G_LOSS_MODE}')\n",
    "\n",
    "# 2-phase controls\n",
    "TRAIN_PHASE = 'phase1'  # 'phase1' | 'phase2'\n",
    "INIT_GEN_PATH = str(Path('.') / 'weights' / 'srresnet_lpips_epoch_20.pth')\n",
    "PHASE2_CKPT = str(Path('.') / 'weights' / 'srgan_60' / 'checkpoint_srgan_60.pth')\n",
    "\n",
    "if TRAIN_PHASE == 'phase1':\n",
    "    cfg['gan']['resume'] = False\n",
    "    cfg['gan']['epochs'] = 60\n",
    "    cfg['gan']['init_gen_path'] = INIT_GEN_PATH\n",
    "elif TRAIN_PHASE == 'phase2':\n",
    "    if not Path(PHASE2_CKPT).exists():\n",
    "        raise FileNotFoundError(f'Phase2 checkpoint not found: {PHASE2_CKPT}')\n",
    "    cfg['gan']['resume'] = True\n",
    "    cfg['gan']['epochs'] = 120\n",
    "    cfg['gan']['checkpoint_path'] = PHASE2_CKPT\n",
    "else:\n",
    "    raise ValueError(f'Unsupported TRAIN_PHASE: {TRAIN_PHASE}')\n",
    "\n",
    "print('TRAIN_PHASE:', TRAIN_PHASE)\n",
    "print('Resume:', cfg['gan']['resume'])\n",
    "print('Epoch target:', cfg['gan']['epochs'])\n",
    "print('G loss mode:', cfg['gan']['g_loss_mode'])\n",
    "print(\n",
    "    f\"LR(G/D)=({cfg['gan']['lr_g']}, {cfg['gan']['lr_d']}) | \"\n",
    "    f\"weights(perc={cfg['gan']['perc_weight']}, lpips={cfg['gan']['lpips_weight']}, adv={cfg['gan']['adv_weight']})\"\n",
    ")\n",
    "print(\n",
    "    f\"G:D steps={cfg['gan']['g_steps']}:{cfg['gan']['d_steps']} | \"\n",
    "    f\"R1={cfg['gan']['r1_weight']}@{cfg['gan']['r1_interval']} | \"\n",
    "    f\"noise={cfg['gan']['d_noise_std_start']}->{cfg['gan']['d_noise_std_end']} ({cfg['gan']['d_noise_decay_epochs']})\"\n",
    ")\n",
    "if cfg['gan']['resume']:\n",
    "    print('Checkpoint path:', cfg['gan']['checkpoint_path'])\n",
    "else:\n",
    "    print('Init generator path:', cfg['gan']['init_gen_path'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "config_path = 'configs/gan_ddp_single.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "\n",
    "ACTIVE_CONFIG_PATH = config_path\n",
    "ACTIVE_TOTAL_EPOCHS = cfg['gan']['epochs']\n",
    "\n",
    "print('Config saved to:', ACTIVE_CONFIG_PATH)\n",
    "print('TOTAL_EPOCHS =', ACTIVE_TOTAL_EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_md",
   "metadata": {},
   "source": [
    "## Run torchrun DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "nproc = torch.cuda.device_count()\n",
    "if nproc < 1:\n",
    "    raise RuntimeError('torchrun DDP requires at least 1 GPU')\n",
    "\n",
    "cmd = [\n",
    "    'torchrun', '--standalone', f'--nproc_per_node={nproc}',\n",
    "    'train_gan_ddp.py', '--config', ACTIVE_CONFIG_PATH\n",
    "]\n",
    "print('Launching:', ' '.join(cmd))\n",
    "\n",
    "RUN_IN_BACKGROUND = True\n",
    "if RUN_IN_BACKGROUND:\n",
    "    proc = subprocess.Popen(cmd)\n",
    "    print(f'Background PID: {proc.pid}')\n",
    "else:\n",
    "    subprocess.run(cmd, check=True)\n",
    "    print('Run finished.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitor_md",
   "metadata": {},
   "source": [
    "## Monitor log and plots (epoch-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "LOG_PATH = 'logs/gan_log.csv'\n",
    "TOTAL_EPOCHS = ACTIVE_TOTAL_EPOCHS\n",
    "REFRESH_SEC = 30\n",
    "\n",
    "\n",
    "def read_log(path):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    try:\n",
    "        with open(path, 'r', newline='') as f:\n",
    "            return list(csv.DictReader(f))\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def render_bar(cur, total, width=30):\n",
    "    if total <= 0:\n",
    "        return '[?]'\n",
    "    cur = min(cur, total)\n",
    "    filled = int(width * cur / total)\n",
    "    return f\"[{'#' * filled}{'.' * (width - filled)}] {cur}/{total}\"\n",
    "\n",
    "\n",
    "def to_float(row, key, default=0.0):\n",
    "    try:\n",
    "        return float(row.get(key, default))\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "\n",
    "\n",
    "while True:\n",
    "    rows = read_log(LOG_PATH)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if not rows:\n",
    "        print('Chua co log. Doi...')\n",
    "        time.sleep(REFRESH_SEC)\n",
    "        continue\n",
    "\n",
    "    last = rows[-1]\n",
    "    epoch = int(last['epoch'])\n",
    "    finished = epoch >= TOTAL_EPOCHS\n",
    "\n",
    "    print('Progress:', render_bar(epoch, TOTAL_EPOCHS))\n",
    "    print(f'Epoch {epoch}/{TOTAL_EPOCHS}')\n",
    "    print(\n",
    "        f\"Train Loss G: {to_float(last, 'train_loss_g'):.4f} | \"\n",
    "        f\"Val Loss G: {to_float(last, 'val_loss_g'):.4f} | \"\n",
    "        f\"Train Loss D: {to_float(last, 'train_loss_d'):.4f} | \"\n",
    "        f\"Val Loss D: {to_float(last, 'val_loss_d'):.4f} | \"\n",
    "        f\"Val PSNR: {to_float(last, 'val_psnr'):.2f} | \"\n",
    "        f\"Val LPIPS: {to_float(last, 'val_lpips'):.4f}\"\n",
    "    )\n",
    "\n",
    "    epochs = [int(r['epoch']) for r in rows]\n",
    "\n",
    "    plots = [\n",
    "        ('loss_g', [to_float(r, 'train_loss_g') for r in rows], [to_float(r, 'val_loss_g') for r in rows]),\n",
    "        ('loss_d', [to_float(r, 'train_loss_d') for r in rows], [to_float(r, 'val_loss_d') for r in rows]),\n",
    "        ('d_real_prob', [to_float(r, 'train_d_real_prob') for r in rows], [to_float(r, 'val_d_real_prob') for r in rows]),\n",
    "        ('d_fake_prob', [to_float(r, 'train_d_fake_prob') for r in rows], [to_float(r, 'val_d_fake_prob') for r in rows]),\n",
    "        ('psnr', [to_float(r, 'train_psnr') for r in rows], [to_float(r, 'val_psnr') for r in rows]),\n",
    "        ('ssim', [to_float(r, 'train_ssim') for r in rows], [to_float(r, 'val_ssim') for r in rows]),\n",
    "        ('lpips', [to_float(r, 'train_lpips') for r in rows], [to_float(r, 'val_lpips') for r in rows]),\n",
    "        ('loss_adv', [to_float(r, 'train_loss_adv') for r in rows], [to_float(r, 'val_loss_adv') for r in rows]),\n",
    "        ('noise_std', [to_float(r, 'noise_std') for r in rows], [to_float(r, 'noise_std') for r in rows]),\n",
    "    ]\n",
    "\n",
    "    ncols = 3\n",
    "    nrows = math.ceil(len(plots) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 4 * nrows))\n",
    "    axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
    "\n",
    "    for i, (title, train_vals, val_vals) in enumerate(plots):\n",
    "        ax = axes[i]\n",
    "        ax.plot(epochs, train_vals, label='train')\n",
    "        ax.plot(epochs, val_vals, label='val')\n",
    "        ax.set_title(title)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "\n",
    "    for j in range(len(plots), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if finished:\n",
    "        val_lpips = [to_float(r, 'val_lpips') for r in rows]\n",
    "        val_psnr = [to_float(r, 'val_psnr') for r in rows]\n",
    "        best_val_lpips = min(val_lpips) if val_lpips else float('nan')\n",
    "        mean_val_psnr_last5 = statistics.mean(val_psnr[-5:]) if val_psnr else float('nan')\n",
    "\n",
    "        print('Training completed. Stopping monitor.')\n",
    "        print(f'Best val LPIPS: {best_val_lpips:.4f}')\n",
    "        print(f'Mean val PSNR (last 5 epochs): {mean_val_psnr_last5:.3f}')\n",
    "        break\n",
    "\n",
    "    time.sleep(REFRESH_SEC)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(venv) Python 3.13.0 (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}