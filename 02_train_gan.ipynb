{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/*\n",
    "# %cd /kaggle/working\n",
    "# !git clone https://github.com/TAYDOVAT/Cuoi_Ki_DL.git\n",
    "# %cd /kaggle/working/Cuoi_Ki_DL\n",
    "\n",
    "# !rm -r /kaggle/working/Cuoi_Ki_DL/test\n",
    "# !rm -r /kaggle/working/Cuoi_Ki_DL/train\n",
    "# !rm -r /kaggle/working/Cuoi_Ki_DL/val\n",
    "\n",
    "# !cp -r \"/kaggle/input/anh-ve-tinh/Ảnh vệ tinh/test\" /kaggle/working/Cuoi_Ki_DL\n",
    "# !cp -r \"/kaggle/input/anh-ve-tinh/Ảnh vệ tinh/train\" /kaggle/working/Cuoi_Ki_DL\n",
    "# !cp -r \"/kaggle/input/anh-ve-tinh/Ảnh vệ tinh/val\" /kaggle/working/Cuoi_Ki_DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SRGAN x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecaef4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\(venv) Python 3.13.0\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from data import build_loader\n",
    "from original_model import SRResNet, DiscriminatorForVGG\n",
    "from losses import PixelLoss, PerceptualLoss, AdversarialLoss\n",
    "from engine import train_gan_epoch, val_gan_epoch\n",
    "from vis import show_lr_sr_hr, plot_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd709ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config override here\n",
    "cfg = {\n",
    "    'scale': 4,\n",
    "    'hr_crop': 96,\n",
    "    'gan': {\n",
    "        'batch_size': 32,\n",
    "        'num_workers': 4,\n",
    "        'epochs': 200,\n",
    "        'lr_g': 1e-6,\n",
    "        'lr_d': 1e-8,\n",
    "        'adv_weight': 1e-3,\n",
    "        'perc_weight': 1,\n",
    "        'pixel_weight': 1,\n",
    "        'load_d': True,\n",
    "        'd_ckpt': 'weights/DiscriminatorForVGG_x4-ImageNet.pth.tar',\n",
    "    },\n",
    "    'paths': {\n",
    "        'train_lr': 'train/train_lr',\n",
    "        'train_hr': 'train/train_hr',\n",
    "        'val_lr': 'val/val_lr',\n",
    "        'val_hr': 'val/val_hr',\n",
    "        'test_lr': 'test/test_lr',\n",
    "        'test_hr': 'test/test_hr',\n",
    "    },\n",
    "}\n",
    "base_dir = None\n",
    "cwd = Path.cwd().resolve()\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    if (parent / 'train' / 'train_lr').is_dir():\n",
    "        base_dir = parent\n",
    "        break\n",
    "\n",
    "if base_dir is None:\n",
    "    raise FileNotFoundError(f\"Cannot find 'train/train_lr' from cwd: {cwd}\")\n",
    "\n",
    "cfg['paths']['train_lr'] = str(base_dir / 'train' / 'train_lr')\n",
    "cfg['paths']['train_hr'] = str(base_dir / 'train' / 'train_hr')\n",
    "cfg['paths']['val_lr'] = str(base_dir / 'val' / 'val_lr')\n",
    "cfg['paths']['val_hr'] = str(base_dir / 'val' / 'val_hr')\n",
    "cfg['paths']['test_lr'] = str(base_dir / 'test' / 'test_lr')\n",
    "cfg['paths']['test_hr'] = str(base_dir / 'test' / 'test_hr')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs('weights', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2aef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_loader = build_loader(\n",
    "    cfg['paths']['train_lr'], cfg['paths']['train_hr'],\n",
    "    scale=cfg['scale'], hr_crop=cfg['hr_crop'],\n",
    "    batch_size=cfg['gan']['batch_size'],\n",
    "    num_workers=cfg['gan']['num_workers'],\n",
    "    train=True\n",
    ")\n",
    "val_dataset, val_loader = build_loader(\n",
    "    cfg['paths']['val_lr'], cfg['paths']['val_hr'],\n",
    "    scale=cfg['scale'], hr_crop=cfg['hr_crop'],\n",
    "    batch_size=32,\n",
    "    num_workers=cfg['gan']['num_workers'],\n",
    "    train=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1388d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SRResNet(upscale=cfg['scale']).to(device)\n",
    "generator.load_state_dict(torch.load('weights/best_srresnet.pth', map_location=device))\n",
    "discriminator = DiscriminatorForVGG().to(device)\n",
    "if cfg['gan'].get('load_d', False):\n",
    "    disc_path = cfg['gan'].get('d_ckpt', 'weights/DiscriminatorForVGG_x4-ImageNet.pth.tar')\n",
    "    disc_ckpt = torch.load(disc_path, map_location=device)\n",
    "    disc_state = disc_ckpt['state_dict'] if isinstance(disc_ckpt, dict) and 'state_dict' in disc_ckpt else disc_ckpt\n",
    "    if isinstance(disc_state, dict) and any(k.startswith('_orig_mod.') for k in disc_state):\n",
    "        disc_state = {k.replace('_orig_mod.', ''): v for k, v in disc_state.items()}\n",
    "    discriminator.load_state_dict(disc_state)\n",
    "\n",
    "pixel_criterion = PixelLoss().to(device)\n",
    "perceptual_criterion = PerceptualLoss().to(device)\n",
    "adversarial_criterion = AdversarialLoss().to(device)\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=cfg['gan']['lr_g'])\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=cfg['gan']['lr_d'])\n",
    "scheduler_g = lr_scheduler.StepLR(optimizer_g, step_size=50, gamma=0.5)\n",
    "scheduler_d = lr_scheduler.StepLR(optimizer_d, step_size=50, gamma=0.5)\n",
    "\n",
    "weights = {\n",
    "    'pixel': cfg['gan']['pixel_weight'],\n",
    "    'perceptual': cfg['gan']['perc_weight'],\n",
    "    'adversarial': cfg['gan']['adv_weight'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 [Train]:   0%|          | 0/1 [00:00<?, ?it/s]e:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 1/200 [Train]:   0%|          | 0/1 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m     28\u001b[39m     train_pbar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Train]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     train_stats = \u001b[43mtrain_gan_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_pbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpixel_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperceptual_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversarial_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     val_pbar = tqdm(val_loader, desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Val]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     37\u001b[39m     val_stats = val_gan_epoch(\n\u001b[32m     38\u001b[39m         generator, discriminator, val_pbar, device,\n\u001b[32m     39\u001b[39m         pixel_criterion, perceptual_criterion, adversarial_criterion,\n\u001b[32m     40\u001b[39m         weights\n\u001b[32m     41\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VietHoang\\Desktop\\Cuoi_Ki_DL\\engine.py:94\u001b[39m, in \u001b[36mtrain_gan_epoch\u001b[39m\u001b[34m(generator, discriminator, loader, optimizer_g, optimizer_d, device, pixel_criterion, perceptual_criterion, adversarial_criterion, weights)\u001b[39m\n\u001b[32m     91\u001b[39m total_ssim = \u001b[32m0.0\u001b[39m\n\u001b[32m     92\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:491\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    489\u001b[39m         \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28mself\u001b[39m._get_iterator()\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1264\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._reset\u001b[39m\u001b[34m(self, loader, first_iter)\u001b[39m\n\u001b[32m   1262\u001b[39m resume_iteration_cnt = \u001b[38;5;28mself\u001b[39m._num_workers\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     return_idx, return_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils.worker._ResumeIteration):\n\u001b[32m   1266\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1454\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1452\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1453\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1454\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1455\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1456\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\(venv) Python 3.13.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\queues.py:111\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    110\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:346\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    344\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:1096\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1093\u001b[39m                 ready_objects.add(o)\n\u001b[32m   1094\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1098\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:1028\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m   1027\u001b[39m     short_L = L[:\u001b[32m60\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(L) > \u001b[32m60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m L\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshort_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m   1030\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'loss_g': {'train': [], 'val': []},\n",
    "    'loss_d': {'train': [], 'val': []},\n",
    "    'psnr': {'train': [], 'val': []},\n",
    "    'ssim': {'train': [], 'val': []},\n",
    "}\n",
    "log_dir = 'logs'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_path = os.path.join(log_dir, 'gan_log.csv')\n",
    "if not os.path.exists(log_path):\n",
    "    with open(log_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            'epoch',\n",
    "            'train_loss_g',\n",
    "            'val_loss_g',\n",
    "            'train_loss_d',\n",
    "            'val_loss_d',\n",
    "            'train_psnr',\n",
    "            'val_psnr',\n",
    "            'train_ssim',\n",
    "            'val_ssim',\n",
    "        ])\n",
    "best_psnr = -1.0\n",
    "epochs = cfg['gan']['epochs']\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{epochs} [Train]')\n",
    "    train_stats = train_gan_epoch(\n",
    "        generator, discriminator, train_pbar,\n",
    "        optimizer_g, optimizer_d, device,\n",
    "        pixel_criterion, perceptual_criterion, adversarial_criterion,\n",
    "        weights\n",
    "    )\n",
    "\n",
    "    val_pbar = tqdm(val_loader, desc=f'Epoch {epoch}/{epochs} [Val]')\n",
    "    val_stats = val_gan_epoch(\n",
    "        generator, discriminator, val_pbar, device,\n",
    "        pixel_criterion, perceptual_criterion, adversarial_criterion,\n",
    "        weights\n",
    "    )\n",
    "\n",
    "    scheduler_g.step()\n",
    "    scheduler_d.step()\n",
    "\n",
    "    history['loss_g']['train'].append(train_stats['loss_g'])\n",
    "    history['loss_g']['val'].append(val_stats['loss_g'])\n",
    "    history['loss_d']['train'].append(train_stats['loss_d'])\n",
    "    history['loss_d']['val'].append(val_stats['loss_d'])\n",
    "    history['psnr']['train'].append(train_stats['psnr'])\n",
    "    history['psnr']['val'].append(val_stats['psnr'])\n",
    "    history['ssim']['train'].append(train_stats['ssim'])\n",
    "    history['ssim']['val'].append(val_stats['ssim'])\n",
    "\n",
    "    with open(log_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            epoch,\n",
    "            train_stats['loss_g'],\n",
    "            val_stats['loss_g'],\n",
    "            train_stats['loss_d'],\n",
    "            val_stats['loss_d'],\n",
    "            train_stats['psnr'],\n",
    "            val_stats['psnr'],\n",
    "            train_stats['ssim'],\n",
    "            val_stats['ssim'],\n",
    "        ])\n",
    "\n",
    "    torch.save(generator.state_dict(), 'weights/last_gan.pth')\n",
    "    if val_stats['psnr'] > best_psnr:\n",
    "        best_psnr = val_stats['psnr']\n",
    "        torch.save(generator.state_dict(), 'weights/best_gan.pth')\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    rand_idx = random.randint(0, len(val_dataset) - 1)\n",
    "    lr_sample, hr_sample = val_dataset[rand_idx]\n",
    "    lr_in = lr_sample.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        sr_sample = generator(lr_in).cpu()\n",
    "    show_lr_sr_hr(lr_sample, sr_sample, hr_sample)\n",
    "\n",
    "    plot_curves(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(venv) Python 3.13.0 (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}