{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5523fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --branch Distributed-Data-Parallel https://github.com/TAYDOVAT/Cuoi_Ki_DL.git\n",
    "# %cd /kaggle/working/Cuoi_Ki_DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Train SRGAN x4 (DDP torchrun)\n",
    "\n",
    "- `resume=False`: load SRResNet weight (`init_gen_path`) + initialize fresh Discriminator.\n",
    "- `resume=True`: load full GAN checkpoint (`checkpoint_path`) to continue training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from configs import CFG\n",
    "\n",
    "cfg = deepcopy(CFG)\n",
    "!pip install lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374af835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config override here\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect data_root (Kaggle + local)\n",
    "candidates = [\n",
    "    Path('/kaggle/input/datasets/tyantran/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('/kaggle/input/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('../../input/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('../input/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "    Path('./datasets/anh-ve-tinh-2/Anh_ve_tinh_2'),\n",
    "]\n",
    "\n",
    "data_root = next((p.resolve() for p in candidates if p.exists()), None)\n",
    "if data_root is None:\n",
    "    raise FileNotFoundError('Khong tim thay data_root. Hay them candidate path phu hop may ban.')\n",
    "print('Using data_root:', data_root)\n",
    "\n",
    "# Paths\n",
    "cfg['paths']['train_lr'] = str(data_root / 'train' / 'train_lr')\n",
    "cfg['paths']['train_hr'] = str(data_root / 'train' / 'train_hr')\n",
    "cfg['paths']['val_lr'] = str(data_root / 'val' / 'val_lr')\n",
    "cfg['paths']['val_hr'] = str(data_root / 'val' / 'val_hr')\n",
    "cfg['paths']['test_lr'] = str(data_root / 'test' / 'test_lr')\n",
    "cfg['paths']['test_hr'] = str(data_root / 'test' / 'test_hr')\n",
    "\n",
    "# Patch size config (HR patch); LR patch = hr_crop // scale\n",
    "cfg['hr_crop'] = 128\n",
    "\n",
    "# GAN train config overrides\n",
    "cfg['gan']['train_batch_size'] = 32\n",
    "cfg['gan']['val_batch_size'] = 12  # None -> auto by world_size\n",
    "cfg['gan']['num_workers'] = 4\n",
    "cfg['gan']['pin_memory'] = True\n",
    "cfg['gan']['persistent_workers'] = True\n",
    "cfg['gan']['epochs'] = 50\n",
    "cfg['gan']['lr_g'] = 1e-4\n",
    "cfg['gan']['lr_d'] = 1e-4\n",
    "cfg['gan']['use_amp'] = True\n",
    "cfg['gan']['use_lpips'] = True  # Set True after: pip install lpips\n",
    "cfg['gan']['g_steps'] = 2\n",
    "cfg['gan']['d_steps'] = 1\n",
    "cfg['gan']['adv_weight'] = 1e-3\n",
    "cfg['gan']['perc_weight'] = 1\n",
    "cfg['gan']['pixel_weight'] = 0\n",
    "cfg['gan']['r1_weight'] = 10\n",
    "cfg['gan']['real_label'] = 0.9\n",
    "cfg['gan']['fake_label'] = 0.1\n",
    "\n",
    "# Label override applies to TRAIN only. Validation keeps default labels (real=1.0, fake=0.0).\n",
    "\n",
    "# Resume mechanism (2 modes only)\n",
    "cfg['gan']['resume'] = False\n",
    "cfg['gan']['init_gen_path'] = str(Path('..') / '..' / 'input' / 'datasets' / 'tyantran' / 'srresnet' / 'srresnet' / 'srresnet_l1_epoch_25.pth')\n",
    "cfg['gan']['checkpoint_path'] = 'weights/srgan_10/checkpoint_srgan_10.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "config_path = 'configs/gan_ddp.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "print('Config saved to:', config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_md",
   "metadata": {},
   "source": [
    "## Run torchrun DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "nproc = torch.cuda.device_count()\n",
    "if nproc < 1:\n",
    "    raise RuntimeError('torchrun DDP requires at least 1 GPU')\n",
    "\n",
    "cmd = [\n",
    "    'torchrun', '--standalone', f'--nproc_per_node={nproc}',\n",
    "    'train_gan_ddp.py', '--config', config_path\n",
    "]\n",
    "print('Launching:', ' '.join(cmd))\n",
    "proc = subprocess.Popen(cmd)\n",
    "print(f'Background PID: {proc.pid}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitor_md",
   "metadata": {},
   "source": [
    "## Monitor log and plots (epoch-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "LOG_PATH = 'logs/gan_log.csv'\n",
    "TOTAL_EPOCHS = cfg['gan']['epochs']\n",
    "REFRESH_SEC = 30\n",
    "\n",
    "def read_log(path):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    try:\n",
    "        with open(path, 'r', newline='') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            return list(reader)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def render_bar(cur, total, width=30):\n",
    "    if total <= 0:\n",
    "        return '[?]'\n",
    "    cur = min(cur, total)\n",
    "    filled = int(width * cur / total)\n",
    "    return f\"[{'#' * filled}{'.' * (width - filled)}] {cur}/{total}\"\n",
    "\n",
    "while True:\n",
    "    rows = read_log(LOG_PATH)\n",
    "    clear_output(wait=True)\n",
    "    if not rows:\n",
    "        print('Chua co log. Doi...')\n",
    "        time.sleep(REFRESH_SEC)\n",
    "        continue\n",
    "\n",
    "    last = rows[-1]\n",
    "    epoch = int(last['epoch'])\n",
    "    finished = epoch >= TOTAL_EPOCHS\n",
    "    print('Progress:', render_bar(epoch, TOTAL_EPOCHS))\n",
    "    print(f'Epoch {epoch}/{TOTAL_EPOCHS}')\n",
    "    print(\n",
    "        f\"Train Loss G: {float(last['train_loss_g']):.4f} | \"\n",
    "        f\"Val Loss G: {float(last['val_loss_g']):.4f} | \"\n",
    "        f\"Train Loss D: {float(last['train_loss_d']):.4f} | \"\n",
    "        f\"Val Loss D: {float(last['val_loss_d']):.4f} | \"\n",
    "        f\"Val PSNR: {float(last['val_psnr']):.2f} | \"\n",
    "        f\"Val LPIPS: {float(last['val_lpips']):.4f}\"\n",
    "    )\n",
    "\n",
    "    epochs = [int(r['epoch']) for r in rows]\n",
    "\n",
    "    train_loss_g = [float(r['train_loss_g']) for r in rows]\n",
    "    val_loss_g = [float(r['val_loss_g']) for r in rows]\n",
    "    train_loss_d = [float(r['train_loss_d']) for r in rows]\n",
    "    val_loss_d = [float(r['val_loss_d']) for r in rows]\n",
    "    train_d_real_prob = [float(r['train_d_real_prob']) for r in rows]\n",
    "    val_d_real_prob = [float(r['val_d_real_prob']) for r in rows]\n",
    "    train_d_fake_prob = [float(r['train_d_fake_prob']) for r in rows]\n",
    "    val_d_fake_prob = [float(r['val_d_fake_prob']) for r in rows]\n",
    "    train_psnr = [float(r['train_psnr']) for r in rows]\n",
    "    val_psnr = [float(r['val_psnr']) for r in rows]\n",
    "    train_ssim = [float(r['train_ssim']) for r in rows]\n",
    "    val_ssim = [float(r['val_ssim']) for r in rows]\n",
    "    train_lpips = [float(r['train_lpips']) for r in rows]\n",
    "    val_lpips = [float(r['val_lpips']) for r in rows]\n",
    "\n",
    "    plots = [\n",
    "        ('loss_g', train_loss_g, val_loss_g),\n",
    "        ('loss_d', train_loss_d, val_loss_d),\n",
    "        ('d_real_prob', train_d_real_prob, val_d_real_prob),\n",
    "        ('d_fake_prob', train_d_fake_prob, val_d_fake_prob),\n",
    "        ('psnr', train_psnr, val_psnr),\n",
    "        ('ssim', train_ssim, val_ssim),\n",
    "        ('lpips', train_lpips, val_lpips),\n",
    "    ]\n",
    "\n",
    "    ncols = 3\n",
    "    nrows = math.ceil(len(plots) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 4 * nrows))\n",
    "    axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
    "\n",
    "    for i, (title, train_vals, val_vals) in enumerate(plots):\n",
    "        ax = axes[i]\n",
    "        ax.plot(epochs, train_vals, label='train')\n",
    "        ax.plot(epochs, val_vals, label='val')\n",
    "        ax.set_title(title)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "\n",
    "    for j in range(len(plots), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if finished:\n",
    "        print('Training completed. Stopping monitor.')\n",
    "        break\n",
    "\n",
    "    time.sleep(REFRESH_SEC)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(venv) Python 3.13.0 (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
