{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from data import PairedSRDataset, build_loader\n",
    "from original_model import SRResNet\n",
    "from metrics import psnr, ssim\n",
    "\n",
    "# Config\n",
    "cfg = {\n",
    "    'scale': 4,\n",
    "    'hr_crop': 128,\n",
    "    'paths': {\n",
    "        'train_lr': 'train/train_lr',\n",
    "        'train_hr': 'train/train_hr',\n",
    "        'val_lr': 'val/val_lr',\n",
    "        'val_hr': 'val/val_hr',\n",
    "        'test_lr': 'test/test_lr',\n",
    "        'test_hr': 'test/test_hr',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Resolve base dir so notebook can run from any cwd\n",
    "base_dir = None\n",
    "cwd = Path.cwd().resolve()\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    if (parent / 'train' / 'train_lr').is_dir():\n",
    "        base_dir = parent\n",
    "        break\n",
    "if base_dir is None:\n",
    "    raise FileNotFoundError(f\"Cannot find 'train/train_lr' from cwd: {cwd}\")\n",
    "\n",
    "cfg['paths']['train_lr'] = str(base_dir / 'train' / 'train_lr')\n",
    "cfg['paths']['train_hr'] = str(base_dir / 'train' / 'train_hr')\n",
    "cfg['paths']['val_lr'] = str(base_dir / 'val' / 'val_lr')\n",
    "cfg['paths']['val_hr'] = str(base_dir / 'val' / 'val_hr')\n",
    "cfg['paths']['test_lr'] = str(base_dir / 'test' / 'test_lr')\n",
    "cfg['paths']['test_hr'] = str(base_dir / 'test' / 'test_hr')\n",
    "\n",
    "# Weight path: prefer repo-local weights; also support Kaggle /kaggle/working layout\n",
    "candidates = [\n",
    "    base_dir / 'weights' / 'best_srresnet.pth',\n",
    "    Path('/kaggle/working') / 'Cuoi_Ki_DL' / 'weights' / 'best_srresnet.pth',\n",
    "]\n",
    "weight_path = None\n",
    "for p in candidates:\n",
    "    if p.is_file():\n",
    "        weight_path = str(p)\n",
    "        break\n",
    "if weight_path is None:\n",
    "    raise FileNotFoundError(f\"Weight not found. Checked: {[str(p) for p in candidates]}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_srresnet(weight_path, scale, device):\n",
    "    model = SRResNet(upscale=scale).to(device)\n",
    "    ckpt = torch.load(weight_path, map_location=device)\n",
    "    if isinstance(ckpt, dict) and any(k in ckpt for k in ['state_dict', 'model', 'generator']):\n",
    "        if 'state_dict' in ckpt:\n",
    "            state = ckpt['state_dict']\n",
    "        elif 'model' in ckpt:\n",
    "            state = ckpt['model']\n",
    "        else:\n",
    "            state = ckpt['generator']\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    # Strip common prefixes if present\n",
    "    if isinstance(state, dict):\n",
    "        if any(k.startswith('module.') for k in state):\n",
    "            state = {k.replace('module.', '', 1): v for k, v in state.items()}\n",
    "        if any(k.startswith('_orig_mod.') for k in state):\n",
    "            state = {k.replace('_orig_mod.', '', 1): v for k, v in state.items()}\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    if missing or unexpected:\n",
    "        print('Missing keys:', missing)\n",
    "        print('Unexpected keys:', unexpected)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_srresnet(weight_path, cfg['scale'], device)\n",
    "\n",
    "# Block 1: evaluate metrics on test set\n",
    "_, test_loader = build_loader(\n",
    "    cfg['paths']['test_lr'], cfg['paths']['test_hr'],\n",
    "    scale=cfg['scale'], hr_crop=cfg['hr_crop'],\n",
    "    batch_size=1, num_workers=4, train=False\n",
    ")\n",
    "\n",
    "psnr_vals = []\n",
    "ssim_vals = []\n",
    "with torch.no_grad():\n",
    "    for lr, hr in tqdm(test_loader, desc='Test'):\n",
    "        lr = lr.to(device)\n",
    "        hr = hr.to(device)\n",
    "        sr = model(lr)\n",
    "        psnr_vals.append(psnr(sr, hr))\n",
    "        ssim_vals.append(ssim(sr, hr))\n",
    "\n",
    "avg_psnr = sum(psnr_vals) / max(len(psnr_vals), 1)\n",
    "avg_ssim = sum(ssim_vals) / max(len(ssim_vals), 1)\n",
    "print(f'Test PSNR: {avg_psnr:.4f} dB')\n",
    "print(f'Test SSIM: {avg_ssim:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: save SR images for test/train/val (batched + JPG)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class PairedSRDatasetWithPaths(PairedSRDataset):\n",
    "    def __getitem__(self, idx):\n",
    "        lr_tensor, hr_tensor = super().__getitem__(idx)\n",
    "        lr_path, hr_path = self.pairs[idx]\n",
    "        return lr_tensor, hr_tensor, lr_path, hr_path\n",
    "\n",
    "def save_sr_split_batched(split_name, lr_dir, hr_dir, out_dir, batch_size=32, num_workers=4, jpg_quality=95):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    dataset = PairedSRDatasetWithPaths(lr_dir, hr_dir, scale=cfg['scale'], hr_crop=cfg['hr_crop'], train=False)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=num_workers > 0,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lr_batch, _, lr_paths, hr_paths in tqdm(loader, desc=f'Saving {split_name}'):\n",
    "            lr_batch = lr_batch.to(device)\n",
    "            sr_batch = model(lr_batch).cpu()\n",
    "            for i in range(sr_batch.size(0)):\n",
    "                base = os.path.splitext(os.path.basename(hr_paths[i]))[0]\n",
    "                if not base:\n",
    "                    base = os.path.splitext(os.path.basename(lr_paths[i]))[0]\n",
    "                out_path = os.path.join(out_dir, f\"{base}_sr.jpg\")\n",
    "                img = TF.to_pil_image(sr_batch[i])\n",
    "                img.save(out_path, format='JPEG', quality=jpg_quality, optimize=True)\n",
    "\n",
    "sr_root = base_dir / 'sr'\n",
    "save_sr_split_batched('test', cfg['paths']['test_lr'], cfg['paths']['test_hr'], str(sr_root / 'test'))\n",
    "save_sr_split_batched('train', cfg['paths']['train_lr'], cfg['paths']['train_hr'], str(sr_root / 'train'))\n",
    "save_sr_split_batched('val', cfg['paths']['val_lr'], cfg['paths']['val_hr'], str(sr_root / 'val'))\n",
    "\n",
    "print('Done saving SR images.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
