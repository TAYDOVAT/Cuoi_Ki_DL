{
    "cells":  [
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "cc70e466",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# !git clone --branch Distributed-Data-Parallel https://github.com/TAYDOVAT/Cuoi_Ki_DL.git\n",
                                     "# %cd /kaggle/working/Cuoi_Ki_DL"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "cfg_base",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from copy import deepcopy\n",
                                     "from configs import CFG\n",
                                     "\n",
                                     "cfg = deepcopy(CFG)\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "dataset_config",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Config override here (dataset)\n",
                                     "from pathlib import Path\n",
                                     "\n",
                                     "# Fixed working directory for relative paths\n",
                                     "cwd = Path(\u0027working/Cuoi_Ki_DL\u0027)\n",
                                     "if not cwd.exists():\n",
                                     "    # Fallback when running from repo root or other cwd\n",
                                     "    alt = Path.cwd() / \u0027working\u0027 / \u0027Cuoi_Ki_DL\u0027\n",
                                     "    if alt.exists():\n",
                                     "        cwd = alt\n",
                                     "    else:\n",
                                     "        # Last-resort: use current working directory\n",
                                     "        cwd = Path.cwd()\n",
                                     "\n",
                                     "data_root = cwd / \u0027..\u0027 / \u0027..\u0027 / \u0027input\u0027 / \u0027datasets\u0027 / \u0027tyantran\u0027 / \u0027anh-ve-tinh-2\u0027 / \u0027Anh_ve_tinh_2\u0027\n",
                                     "\n",
                                     "cfg[\u0027paths\u0027][\u0027test_lr\u0027] = str(data_root / \u0027test\u0027 / \u0027test_lr\u0027)\n",
                                     "cfg[\u0027paths\u0027][\u0027test_hr\u0027] = str(data_root / \u0027test\u0027 / \u0027test_hr\u0027)\n",
                                     "\n",
                                     "print(\u0027CWD:\u0027, cwd)\n",
                                     "print(\u0027Test LR:\u0027, cfg[\u0027paths\u0027][\u0027test_lr\u0027])\n",
                                     "print(\u0027Test HR:\u0027, cfg[\u0027paths\u0027][\u0027test_hr\u0027])\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "weights_config",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Weights config (relative paths)\n",
                                     "from pathlib import Path\n",
                                     "\n",
                                     "# Fixed working directory for relative paths\n",
                                     "cwd = Path(\u0027working/Cuoi_Ki_DL\u0027)\n",
                                     "if not cwd.exists():\n",
                                     "    # Fallback when running from repo root or other cwd\n",
                                     "    alt = Path.cwd() / \u0027working\u0027 / \u0027Cuoi_Ki_DL\u0027\n",
                                     "    if alt.exists():\n",
                                     "        cwd = alt\n",
                                     "    else:\n",
                                     "        # Last-resort: use current working directory\n",
                                     "        cwd = Path.cwd()\n",
                                     "\n",
                                     "weights_dir = cwd / \u0027..\u0027 / \u0027..\u0027 / \u0027input\u0027 / \u0027datasets\u0027 / \u0027tyantran\u0027 / \u0027srresnet\u0027 / \u0027srresnet\u0027\n",
                                     "# Choose one: srresnet_lpips_epoch_20.pth | srresnet_l1_epoch_25.pth | srresnet_ssim_epoch_69.pth\n",
                                     "weights_name = \u0027srresnet_l1_epoch_25.pth\u0027\n",
                                     "weights_path = weights_dir / weights_name\n",
                                     "\n",
                                     "print(\u0027Weights:\u0027, weights_path)\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "eval_config",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Evaluation config (edit all evaluation-related settings here)\n",
                                     "from pathlib import Path\n",
                                     "\n",
                                     "# Fixed working directory for relative paths\n",
                                     "cwd = Path(\u0027working/Cuoi_Ki_DL\u0027)\n",
                                     "if not cwd.exists():\n",
                                     "    # Fallback when running from repo root or other cwd\n",
                                     "    alt = Path.cwd() / \u0027working\u0027 / \u0027Cuoi_Ki_DL\u0027\n",
                                     "    if alt.exists():\n",
                                     "        cwd = alt\n",
                                     "    else:\n",
                                     "        # Last-resort: use current working directory\n",
                                     "        cwd = Path.cwd()\n",
                                     "\n",
                                     "eval_cfg = {\n",
                                     "    \u0027batch_size\u0027: 12,\n",
                                     "    \u0027num_workers\u0027: 4,\n",
                                     "    \u0027use_amp\u0027: True,\n",
                                     "    \u0027device\u0027: \u0027cuda\u0027,\n",
                                     "    \u0027compute_psnr\u0027: True,\n",
                                     "    \u0027compute_ssim\u0027: True,\n",
                                     "    \u0027compute_lpips\u0027: True,\n",
                                     "    \u0027lpips_net\u0027: \u0027vgg\u0027,\n",
                                     "    \u0027save_sr\u0027: True,\n",
                                     "    \u0027save_dir\u0027: str(cwd / \u0027..\u0027 / \u0027..\u0027 / \u0027outputs\u0027 / \u0027srresnet_test\u0027),\n",
                                     "    \u0027max_images\u0027: None,\n",
                                     "}\n",
                                     "\n",
                                     "print(\u0027Eval config:\u0027, eval_cfg)\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "install_lpips",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "!pip install lpips\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "load_model",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import torch\n",
                                     "from original_model import SRResNet\n",
                                     "from data import build_loader\n",
                                     "from metrics import psnr, ssim\n",
                                     "\n",
                                     "device = torch.device(eval_cfg[\u0027device\u0027] if torch.cuda.is_available() and eval_cfg[\u0027device\u0027] == \u0027cuda\u0027 else \u0027cpu\u0027)\n",
                                     "print(\u0027Device:\u0027, device)\n",
                                     "\n",
                                     "model = SRResNet(upscale=cfg[\u0027scale\u0027])\n",
                                     "state = torch.load(weights_path, map_location=\u0027cpu\u0027)\n",
                                     "if isinstance(state, dict):\n",
                                     "    if \u0027model_state_dict\u0027 in state:\n",
                                     "        state = state[\u0027model_state_dict\u0027]\n",
                                     "    elif \u0027generator_state_dict\u0027 in state:\n",
                                     "        state = state[\u0027generator_state_dict\u0027]\n",
                                     "model.load_state_dict(state)\n",
                                     "model.to(device)\n",
                                     "model.eval()\n",
                                     "print(\u0027Loaded weights OK\u0027)\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "build_loader",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "test_lr = cfg[\u0027paths\u0027][\u0027test_lr\u0027]\n",
                                     "test_hr = cfg[\u0027paths\u0027][\u0027test_hr\u0027]\n",
                                     "\n",
                                     "dataset, loader = build_loader(\n",
                                     "    lr_dir=test_lr,\n",
                                     "    hr_dir=test_hr,\n",
                                     "    scale=cfg[\u0027scale\u0027],\n",
                                     "    hr_crop=cfg[\u0027hr_crop\u0027],\n",
                                     "    batch_size=eval_cfg[\u0027batch_size\u0027],\n",
                                     "    num_workers=eval_cfg[\u0027num_workers\u0027],\n",
                                     "    train=False,\n",
                                     ")\n",
                                     "\n",
                                     "print(\u0027Test samples:\u0027, len(dataset))\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "eval_and_save",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import os\n",
                                     "from pathlib import Path\n",
                                     "from torchvision.transforms import functional as TF\n",
                                     "\n",
                                     "try:\n",
                                     "    import lpips\n",
                                     "except Exception as e:\n",
                                     "    lpips = None\n",
                                     "    print(\u0027LPIPS not available:\u0027, e)\n",
                                     "\n",
                                     "lpips_metric = None\n",
                                     "if eval_cfg[\u0027compute_lpips\u0027] and lpips is not None:\n",
                                     "    lpips_metric = lpips.LPIPS(net=eval_cfg[\u0027lpips_net\u0027]).to(device)\n",
                                     "    lpips_metric.eval()\n",
                                     "\n",
                                     "save_dir = Path(eval_cfg[\u0027save_dir\u0027])\n",
                                     "if eval_cfg[\u0027save_sr\u0027]:\n",
                                     "    save_dir.mkdir(parents=True, exist_ok=True)\n",
                                     "\n",
                                     "total_psnr = 0.0\n",
                                     "total_ssim = 0.0\n",
                                     "total_lpips = 0.0\n",
                                     "metric_count = 0\n",
                                     "img_index = 0\n",
                                     "\n",
                                     "max_images = eval_cfg[\u0027max_images\u0027]\n",
                                     "\n",
                                     "device_type = device.type if hasattr(device, \u0027type\u0027) else \u0027cpu\u0027\n",
                                     "\n",
                                     "with torch.no_grad():\\n\n",
                                     "# Progress tracking (no tqdm)\n",
                                     "try:\n",
                                     "    total_images = len(dataset.pairs)\n",
                                     "except Exception:\n",
                                     "    total_images = None\n",
                                     "print_every = 10  # batches    for i, (lr, hr) in enumerate(loader):\n",
                                     "        if max_images is not None and img_index \u003e= max_images:\n",
                                     "            break\n",
                                     "\n",
                                     "        lr = lr.to(device, non_blocking=True)\n",
                                     "        hr = hr.to(device, non_blocking=True)\n",
                                     "\n",
                                     "        with torch.amp.autocast(device_type=device_type, enabled=eval_cfg[\u0027use_amp\u0027]):\n",
                                     "            sr = model(lr)\n",
                                     "\n",
                                     "        sr_clip = sr.clamp(0.0, 1.0)\n",
                                     "        batch_size = lr.size(0)\n",
                                     "\n",
                                     "        if eval_cfg[\u0027compute_psnr\u0027]:\n",
                                     "            total_psnr += psnr(sr_clip.float(), hr.float()) * batch_size\n",
                                     "        if eval_cfg[\u0027compute_ssim\u0027]:\n",
                                     "            total_ssim += ssim(sr_clip.float(), hr.float()) * batch_size\n",
                                     "        if lpips_metric is not None:\n",
                                     "            sr_norm = sr_clip * 2.0 - 1.0\n",
                                     "            hr_norm = hr * 2.0 - 1.0\n",
                                     "            total_lpips += lpips_metric(sr_norm, hr_norm).mean().item() * batch_size\n",
                                     "\n",
                                     "        metric_count += batch_size\\n\\n        if (i + 1) % print_every == 0:\\n            if total_images is None:\\n                print(f\u0027Processed {img_index + batch_size} images (batch {i+1})\u0027)\\n            else:\\n                done = min(img_index + batch_size, total_images)\\n                print(f\u0027Processed {done}/{total_images} images (batch {i+1})\u0027)\\n\\n        # Save SR images\n",
                                     "        if eval_cfg[\u0027save_sr\u0027]:\n",
                                     "            batch = sr_clip.cpu()\n",
                                     "            for b in range(batch.size(0)):\n",
                                     "                if max_images is not None and img_index \u003e= max_images:\n",
                                     "                    break\n",
                                     "                lr_path, hr_path = dataset.pairs[img_index]\n",
                                     "                stem = Path(lr_path).stem\n",
                                     "                out_path = save_dir / f\u0027{stem}_SR.png\u0027\n",
                                     "                img = TF.to_pil_image(batch[b])\n",
                                     "                img.save(out_path)\n",
                                     "                img_index += 1\n",
                                     "        else:\n",
                                     "            img_index += batch_size\n",
                                     "\n",
                                     "if metric_count == 0:\n",
                                     "    raise RuntimeError(\u0027No samples processed.\u0027)\n",
                                     "\n",
                                     "avg_psnr = total_psnr / metric_count if eval_cfg[\u0027compute_psnr\u0027] else 0.0\n",
                                     "avg_ssim = total_ssim / metric_count if eval_cfg[\u0027compute_ssim\u0027] else 0.0\n",
                                     "avg_lpips = total_lpips / metric_count if lpips_metric is not None else 0.0\n",
                                     "\n",
                                     "print(f\u0027PSNR: {avg_psnr:.4f}\u0027)\n",
                                     "print(f\u0027SSIM: {avg_ssim:.4f}\u0027)\n",
                                     "print(f\u0027LPIPS: {avg_lpips:.4f}\u0027)\n",
                                     "print(\u0027Saved to:\u0027, save_dir if eval_cfg[\u0027save_sr\u0027] else \u0027N/A\u0027)\n",
                                     ""
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "(venv) Python 3.13.0 (3.13.0)",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "name":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.13.0"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
