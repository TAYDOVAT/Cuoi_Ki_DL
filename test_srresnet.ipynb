{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --branch Distributed-Data-Parallel https://github.com/TAYDOVAT/Cuoi_Ki_DL.git\n",
    "# %cd /kaggle/working/Cuoi_Ki_DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfg_base",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from configs import CFG\n",
    "\n",
    "cfg = deepcopy(CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config override here (dataset)\n",
    "from pathlib import Path\n",
    "\n",
    "# Fixed working directory for relative paths\n",
    "cwd = Path('working/Cuoi_Ki_DL')\n",
    "if not cwd.exists():\n",
    "    # Fallback when running from repo root or other cwd\n",
    "    alt = Path.cwd() / 'working' / 'Cuoi_Ki_DL'\n",
    "    if alt.exists():\n",
    "        cwd = alt\n",
    "    else:\n",
    "        # Last-resort: use current working directory\n",
    "        cwd = Path.cwd()\n",
    "\n",
    "data_root = cwd / '..' / '..' / 'input' / 'datasets' / 'tyantran' / 'anh-ve-tinh-2' / 'Anh_ve_tinh_2'\n",
    "\n",
    "cfg['paths']['test_lr'] = str(data_root / 'test' / 'test_lr')\n",
    "cfg['paths']['test_hr'] = str(data_root / 'test' / 'test_hr')\n",
    "\n",
    "print('CWD:', cwd)\n",
    "print('Test LR:', cfg['paths']['test_lr'])\n",
    "print('Test HR:', cfg['paths']['test_hr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weights_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights config (relative paths)\n",
    "from pathlib import Path\n",
    "\n",
    "# Fixed working directory for relative paths\n",
    "cwd = Path('working/Cuoi_Ki_DL')\n",
    "if not cwd.exists():\n",
    "    # Fallback when running from repo root or other cwd\n",
    "    alt = Path.cwd() / 'working' / 'Cuoi_Ki_DL'\n",
    "    if alt.exists():\n",
    "        cwd = alt\n",
    "    else:\n",
    "        # Last-resort: use current working directory\n",
    "        cwd = Path.cwd()\n",
    "\n",
    "weights_dir = cwd / '..' / '..' / 'input' / 'datasets' / 'tyantran' / 'srresnet' / 'srresnet'\n",
    "# Choose one: srresnet_lpips_epoch_20.pth | srresnet_l1_epoch_25.pth | srresnet_ssim_epoch_69.pth\n",
    "weights_name = 'srresnet_l1_epoch_25.pth'\n",
    "weights_path = weights_dir / weights_name\n",
    "\n",
    "print('Weights:', weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation config (edit all evaluation-related settings here)\n",
    "from pathlib import Path\n",
    "\n",
    "# Fixed working directory for relative paths\n",
    "cwd = Path('working/Cuoi_Ki_DL')\n",
    "if not cwd.exists():\n",
    "    # Fallback when running from repo root or other cwd\n",
    "    alt = Path.cwd() / 'working' / 'Cuoi_Ki_DL'\n",
    "    if alt.exists():\n",
    "        cwd = alt\n",
    "    else:\n",
    "        # Last-resort: use current working directory\n",
    "        cwd = Path.cwd()\n",
    "\n",
    "eval_cfg = {\n",
    "    'batch_size': 1,\n",
    "    'num_workers': 2,\n",
    "    'use_amp': True,\n",
    "    'device': 'cuda',\n",
    "    'compute_psnr': True,\n",
    "    'compute_ssim': True,\n",
    "    'compute_lpips': True,\n",
    "    'lpips_net': 'vgg',\n",
    "    'save_sr': True,\n",
    "    'save_dir': str(cwd / '..' / '..' / 'outputs' / 'srresnet_test'),\n",
    "    'max_images': None,\n",
    "}\n",
    "\n",
    "print('Eval config:', eval_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_lpips",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install lpips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import SRResNet\n",
    "from data import build_loader\n",
    "from metrics import psnr, ssim\n",
    "\n",
    "device = torch.device(eval_cfg['device'] if torch.cuda.is_available() and eval_cfg['device'] == 'cuda' else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "model = SRResNet(scale=cfg['scale'])\n",
    "state = torch.load(weights_path, map_location='cpu')\n",
    "if isinstance(state, dict):\n",
    "    if 'model_state_dict' in state:\n",
    "        state = state['model_state_dict']\n",
    "    elif 'generator_state_dict' in state:\n",
    "        state = state['generator_state_dict']\n",
    "model.load_state_dict(state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('Loaded weights OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_loader",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lr = cfg['paths']['test_lr']\n",
    "test_hr = cfg['paths']['test_hr']\n",
    "\n",
    "dataset, loader = build_loader(\n",
    "    lr_dir=test_lr,\n",
    "    hr_dir=test_hr,\n",
    "    scale=cfg['scale'],\n",
    "    hr_crop=cfg['hr_crop'],\n",
    "    batch_size=eval_cfg['batch_size'],\n",
    "    num_workers=eval_cfg['num_workers'],\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "print('Test samples:', len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_and_save",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "try:\n",
    "    import lpips\n",
    "except Exception as e:\n",
    "    lpips = None\n",
    "    print('LPIPS not available:', e)\n",
    "\n",
    "lpips_metric = None\n",
    "if eval_cfg['compute_lpips'] and lpips is not None:\n",
    "    lpips_metric = lpips.LPIPS(net=eval_cfg['lpips_net']).to(device)\n",
    "    lpips_metric.eval()\n",
    "\n",
    "save_dir = Path(eval_cfg['save_dir'])\n",
    "if eval_cfg['save_sr']:\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "total_psnr = 0.0\n",
    "total_ssim = 0.0\n",
    "total_lpips = 0.0\n",
    "metric_count = 0\n",
    "img_index = 0\n",
    "\n",
    "max_images = eval_cfg['max_images']\n",
    "\n",
    "device_type = device.type if hasattr(device, 'type') else 'cpu'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (lr, hr) in enumerate(loader):\n",
    "        if max_images is not None and img_index >= max_images:\n",
    "            break\n",
    "\n",
    "        lr = lr.to(device, non_blocking=True)\n",
    "        hr = hr.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type=device_type, enabled=eval_cfg['use_amp']):\n",
    "            sr = model(lr)\n",
    "\n",
    "        sr_clip = sr.clamp(0.0, 1.0)\n",
    "        batch_size = lr.size(0)\n",
    "\n",
    "        if eval_cfg['compute_psnr']:\n",
    "            total_psnr += psnr(sr_clip.float(), hr.float()) * batch_size\n",
    "        if eval_cfg['compute_ssim']:\n",
    "            total_ssim += ssim(sr_clip.float(), hr.float()) * batch_size\n",
    "        if lpips_metric is not None:\n",
    "            sr_norm = sr_clip * 2.0 - 1.0\n",
    "            hr_norm = hr * 2.0 - 1.0\n",
    "            total_lpips += lpips_metric(sr_norm, hr_norm).mean().item() * batch_size\n",
    "\n",
    "        metric_count += batch_size\n",
    "\n",
    "        # Save SR images\n",
    "        if eval_cfg['save_sr']:\n",
    "            batch = sr_clip.cpu()\n",
    "            for b in range(batch.size(0)):\n",
    "                if max_images is not None and img_index >= max_images:\n",
    "                    break\n",
    "                lr_path, hr_path = dataset.pairs[img_index]\n",
    "                stem = Path(lr_path).stem\n",
    "                out_path = save_dir / f'{stem}_SR.png'\n",
    "                img = TF.to_pil_image(batch[b])\n",
    "                img.save(out_path)\n",
    "                img_index += 1\n",
    "        else:\n",
    "            img_index += batch_size\n",
    "\n",
    "if metric_count == 0:\n",
    "    raise RuntimeError('No samples processed.')\n",
    "\n",
    "avg_psnr = total_psnr / metric_count if eval_cfg['compute_psnr'] else 0.0\n",
    "avg_ssim = total_ssim / metric_count if eval_cfg['compute_ssim'] else 0.0\n",
    "avg_lpips = total_lpips / metric_count if lpips_metric is not None else 0.0\n",
    "\n",
    "print(f'PSNR: {avg_psnr:.4f}')\n",
    "print(f'SSIM: {avg_ssim:.4f}')\n",
    "print(f'LPIPS: {avg_lpips:.4f}')\n",
    "print('Saved to:', save_dir if eval_cfg['save_sr'] else 'N/A')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(venv) Python 3.13.0 (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
