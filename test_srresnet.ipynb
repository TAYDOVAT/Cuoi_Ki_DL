{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from data import PairedSRDataset, build_loader\n",
    "from model import SRResNet\n",
    "from metrics import psnr, ssim\n",
    "\n",
    "# Config\n",
    "cfg = {\n",
    "    'scale': 4,\n",
    "    'hr_crop': 128,\n",
    "    'paths': {\n",
    "        'train_lr': 'train/train_lr',\n",
    "        'train_hr': 'train/train_hr',\n",
    "        'val_lr': 'val/val_lr',\n",
    "        'val_hr': 'val/val_hr',\n",
    "        'test_lr': 'test/test_lr',\n",
    "        'test_hr': 'test/test_hr',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Resolve base dir so notebook can run from any cwd\n",
    "base_dir = None\n",
    "cwd = Path.cwd().resolve()\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    if (parent / 'train' / 'train_lr').is_dir():\n",
    "        base_dir = parent\n",
    "        break\n",
    "if base_dir is None:\n",
    "    raise FileNotFoundError(f\"Cannot find 'train/train_lr' from cwd: {cwd}\")\n",
    "\n",
    "cfg['paths']['train_lr'] = str(base_dir / 'train' / 'train_lr')\n",
    "cfg['paths']['train_hr'] = str(base_dir / 'train' / 'train_hr')\n",
    "cfg['paths']['val_lr'] = str(base_dir / 'val' / 'val_lr')\n",
    "cfg['paths']['val_hr'] = str(base_dir / 'val' / 'val_hr')\n",
    "cfg['paths']['test_lr'] = str(base_dir / 'test' / 'test_lr')\n",
    "cfg['paths']['test_hr'] = str(base_dir / 'test' / 'test_hr')\n",
    "\n",
    "weight_path = r\"C:\\\\Users\\\\VietHoang\\\\Desktop\\\\Cuoi_Ki_DL\\\\weights\\\\best_srresnet.pth\"\n",
    "if not os.path.isfile(weight_path):\n",
    "    raise FileNotFoundError(f\"Weight not found: {weight_path}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_srresnet(weight_path, scale, device):\n",
    "    model = SRResNet(scale=scale).to(device)\n",
    "    ckpt = torch.load(weight_path, map_location=device)\n",
    "    if isinstance(ckpt, dict) and any(k in ckpt for k in ['state_dict', 'model', 'generator']):\n",
    "        if 'state_dict' in ckpt:\n",
    "            state = ckpt['state_dict']\n",
    "        elif 'model' in ckpt:\n",
    "            state = ckpt['model']\n",
    "        else:\n",
    "            state = ckpt['generator']\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    # Strip common prefixes if present\n",
    "    if isinstance(state, dict):\n",
    "        if any(k.startswith('module.') for k in state):\n",
    "            state = {k.replace('module.', '', 1): v for k, v in state.items()}\n",
    "        if any(k.startswith('_orig_mod.') for k in state):\n",
    "            state = {k.replace('_orig_mod.', '', 1): v for k, v in state.items()}\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    if missing or unexpected:\n",
    "        print('Missing keys:', missing)\n",
    "        print('Unexpected keys:', unexpected)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_srresnet(weight_path, cfg['scale'], device)\n",
    "\n",
    "# Block 1: evaluate metrics on test set\n",
    "_, test_loader = build_loader(\n",
    "    cfg['paths']['test_lr'], cfg['paths']['test_hr'],\n",
    "    scale=cfg['scale'], hr_crop=cfg['hr_crop'],\n",
    "    batch_size=1, num_workers=4, train=False\n",
    ")\n",
    "\n",
    "psnr_vals = []\n",
    "ssim_vals = []\n",
    "with torch.no_grad():\n",
    "    for lr, hr in tqdm(test_loader, desc='Test'):\n",
    "        lr = lr.to(device)\n",
    "        hr = hr.to(device)\n",
    "        sr = model(lr)\n",
    "        psnr_vals.append(psnr(sr, hr))\n",
    "        ssim_vals.append(ssim(sr, hr))\n",
    "\n",
    "avg_psnr = sum(psnr_vals) / max(len(psnr_vals), 1)\n",
    "avg_ssim = sum(ssim_vals) / max(len(ssim_vals), 1)\n",
    "print(f'Test PSNR: {avg_psnr:.4f} dB')\n",
    "print(f'Test SSIM: {avg_ssim:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: save SR images for test/train/val\n",
    "def save_sr_split(split_name, lr_dir, hr_dir, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    dataset = PairedSRDataset(lr_dir, hr_dir, scale=cfg['scale'], hr_crop=cfg['hr_crop'], train=False)\n",
    "    pairs = dataset.pairs\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lr_path, hr_path in tqdm(pairs, desc=f'Saving {split_name}'):\n",
    "            lr_img = TF.to_tensor(dataset._load(lr_path)).unsqueeze(0).to(device)\n",
    "            sr = model(lr_img).cpu()\n",
    "\n",
    "            base = os.path.splitext(os.path.basename(hr_path))[0]\n",
    "            if not base:\n",
    "                base = os.path.splitext(os.path.basename(lr_path))[0]\n",
    "            out_path = os.path.join(out_dir, f\"{base}_sr.png\")\n",
    "            save_image(sr, out_path)\n",
    "\n",
    "sr_root = base_dir / 'sr'\n",
    "save_sr_split('test', cfg['paths']['test_lr'], cfg['paths']['test_hr'], str(sr_root / 'test'))\n",
    "save_sr_split('train', cfg['paths']['train_lr'], cfg['paths']['train_hr'], str(sr_root / 'train'))\n",
    "save_sr_split('val', cfg['paths']['val_lr'], cfg['paths']['val_hr'], str(sr_root / 'val'))\n",
    "\n",
    "print('Done saving SR images.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
